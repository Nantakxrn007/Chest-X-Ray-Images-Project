{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eecdbb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.training_args\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (\n",
    "    ViTFeatureExtractor,\n",
    "    ViTForImageClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from PIL import Image\n",
    "from transformers import TrainingArguments\n",
    "print(TrainingArguments.__module__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2aec0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4608010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"chest_xray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2a4f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 5216\n",
      "Val samples: 16\n",
      "Test samples: 624\n",
      "Classes: ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.ImageFolder(root=f\"{data_dir}/train\")\n",
    "val_dataset   = datasets.ImageFolder(root=f\"{data_dir}/val\")\n",
    "test_dataset  = datasets.ImageFolder(root=f\"{data_dir}/test\")\n",
    "\n",
    "print(\"Train samples:\", len(train_dataset))\n",
    "print(\"Val samples:\", len(val_dataset))\n",
    "print(\"Test samples:\", len(test_dataset))\n",
    "print(\"Classes:\", train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b1e546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "def vit_transform(image):\n",
    "    return extractor(images=image, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)\n",
    "\n",
    "train_dataset.transform = vit_transform\n",
    "val_dataset.transform   = vit_transform\n",
    "test_dataset.transform  = vit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad1f6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFDataset(Dataset):\n",
    "    def __init__(self, folder_dataset):\n",
    "        self.dataset = folder_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        return {\"pixel_values\": img, \"labels\": label}\n",
    "\n",
    "train_dataset_hf = HFDataset(train_dataset)\n",
    "val_dataset_hf   = HFDataset(val_dataset)\n",
    "test_dataset_hf  = HFDataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6dafa03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NORMAL\", 1: \"PNEUMONIA\"},\n",
    "    label2id={\"NORMAL\": 0, \"PNEUMONIA\": 1},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "526fe7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vit_xray_results\",\n",
    "    evaluation_strategy=\"epoch\",     # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡πá‡∏°!\n",
    "    save_strategy=\"epoch\",           # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏∏‡∏Å epoch\n",
    "    learning_rate=3e-5,              # üëà ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö ViT\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=8,              # üëà ‡πÄ‡∏û‡∏¥‡πà‡∏° epoch ‡πÉ‡∏´‡πâ ViT fine-tune ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\", # ‡πÉ‡∏ä‡πâ accuracy ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "    greater_is_better=True,           # ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ accuracy ‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ\n",
    "    lr_scheduler_type=\"cosine\",       # üëà ‡πÉ‡∏ä‡πâ cosine schedule (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö fine-tuning)\n",
    "    warmup_ratio=0.1,                 # üëà warmup 10% ‡∏Ç‡∏≠‡∏á steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42f7d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a922a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 281/1630 [10:39<51:10,  2.28s/it]\n",
      "                                                  \n",
      "  2%|‚ñè         | 50/2608 [00:46<38:14,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6359, 'grad_norm': 0.9570462703704834, 'learning_rate': 5.747126436781609e-06, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  4%|‚ñç         | 100/2608 [01:33<39:02,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3556, 'grad_norm': 2.292985439300537, 'learning_rate': 1.1494252873563218e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  6%|‚ñå         | 150/2608 [02:20<38:08,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1781, 'grad_norm': 1.2274476289749146, 'learning_rate': 1.7241379310344828e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  8%|‚ñä         | 200/2608 [03:06<36:50,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0874, 'grad_norm': 6.357956409454346, 'learning_rate': 2.2988505747126437e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 10%|‚ñâ         | 250/2608 [03:53<36:36,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0943, 'grad_norm': 4.9710516929626465, 'learning_rate': 2.8735632183908045e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 12%|‚ñà‚ñè        | 300/2608 [05:01<1:27:48,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1288, 'grad_norm': 0.7385244369506836, 'learning_rate': 2.9979565434294196e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñé        | 326/2608 [05:57<1:01:20,  1.61s/it]\n",
      "                                                    \n",
      "\u001b[A                                              \n",
      "\n",
      " 12%|‚ñà‚ñé        | 326/2608 [05:58<1:01:20,  1.61s/it]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15796920657157898, 'eval_accuracy': 0.9375, 'eval_runtime': 1.1633, 'eval_samples_per_second': 13.754, 'eval_steps_per_second': 0.86, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 13%|‚ñà‚ñé        | 350/2608 [06:26<40:43,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0631, 'grad_norm': 0.1262059509754181, 'learning_rate': 2.9893683384022836e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 15%|‚ñà‚ñå        | 400/2608 [07:30<36:44,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0487, 'grad_norm': 7.311153411865234, 'learning_rate': 2.974111243076491e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 17%|‚ñà‚ñã        | 450/2608 [08:26<33:33,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0687, 'grad_norm': 0.14053528010845184, 'learning_rate': 2.9522535735914266e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 19%|‚ñà‚ñâ        | 500/2608 [09:12<33:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0647, 'grad_norm': 7.382377624511719, 'learning_rate': 2.9238932012366986e-05, 'epoch': 1.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 21%|‚ñà‚ñà        | 550/2608 [10:15<59:03,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0456, 'grad_norm': 1.0640891790390015, 'learning_rate': 2.8891571142174315e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 23%|‚ñà‚ñà‚ñé       | 600/2608 [11:07<35:32,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0682, 'grad_norm': 0.05844239145517349, 'learning_rate': 2.8482008490438112e-05, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 25%|‚ñà‚ñà‚ñç       | 650/2608 [12:31<59:07,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0677, 'grad_norm': 0.43423500657081604, 'learning_rate': 2.8012077940909242e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 652/2608 [12:33<46:39,  1.43s/it]\n",
      "\u001b[A\n",
      "\n",
      "                                                  \n",
      "\u001b[A                                              \n",
      " 25%|‚ñà‚ñà‚ñå       | 652/2608 [12:35<46:39,  1.43s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5480027794837952, 'eval_accuracy': 0.75, 'eval_runtime': 1.4737, 'eval_samples_per_second': 10.857, 'eval_steps_per_second': 0.679, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 683/2608 [13:29<53:00,  1.65s/it]  "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_hf,\n",
    "    eval_dataset=val_dataset_hf,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on test dataset...\")\n",
    "metrics = trainer.evaluate(test_dataset_hf)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e08a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./vit_xray_finetuned\")\n",
    "print(\"Model saved to ./vit_xray_finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
